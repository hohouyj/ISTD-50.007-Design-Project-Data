{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Markov Pog",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6y3-lc6Gmf2"
      },
      "source": [
        "ISTD 50.007 Machine Learning\n",
        "\n",
        "Design Project 2020\n",
        "\n",
        "Group 27\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PaMpZh4K6zN",
        "outputId": "e4c1df8a-ef88-4230-cfff-416507328c7b"
      },
      "source": [
        "!git clone https://github.com/hohouyj/ISTD-50.007-Design-Project-Data.git"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fatal: destination path 'ISTD-50.007-Design-Project-Data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7gtufCM44t"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YNAyUn1HIF8"
      },
      "source": [
        "Part 2: MLE Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E7RSJzROyHi"
      },
      "source": [
        "Get the dumass fkin shit ass, mother fucking data\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1CKB0l5HHsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01513366-0249-4cc8-dae4-787afba5856b"
      },
      "source": [
        "#ENtrain = pd.read_table('/content/ISTD-50.007-Design-Project-Data/EN/train', header = None, delimiter = ' ')\n",
        "#CNtrain = pd.read_table('/content/ISTD-50.007-Design-Project-Data/CN/train', header = None, delimiter = ' ')\n",
        "#SGtrain = pd.read_table('/content/ISTD-50.007-Design-Project-Data/SG/train', header = None, delimiter = ' ')\n",
        "\n",
        "def read_data_file(file_loc):\n",
        "  re_df = []\n",
        "  with open(file_loc,'r',encoding=\"utf8\") as f:\n",
        "    for i in f.readlines():\n",
        "      if i == '\\n':\n",
        "        pass\n",
        "      elif i[-1:] == '\\n':\n",
        "        ls = i[:-1].split(' ')\n",
        "        test_str = 'q'+ls[0]+'q'\n",
        "        if test_str == 'q️q': #pls dont delete invisible char here\n",
        "          #print(file_loc,ls)\n",
        "          try:\n",
        "            ls1 = ['#SPACE#', ls[1]]\n",
        "            re_df.append(ls1)\n",
        "          except:\n",
        "            print(f'excepted {ls} in {file_loc}')\n",
        "        else:\n",
        "          re_df.append(ls)\n",
        "    re_df = pd.DataFrame(re_df)\n",
        "  return re_df\n",
        "\n",
        "ENtrain = read_data_file('content/ISTD-50.007-Design-Project-Data/EN/train')\n",
        "CNtrain = read_data_file('content/ISTD-50.007-Design-Project-Data/CN/train')\n",
        "SGtrain = read_data_file('content/ISTD-50.007-Design-Project-Data/SG/train')\n",
        "ENtest = read_data_file('content/ISTD-50.007-Design-Project-Data/EN/dev.in')\n",
        "CNtest = read_data_file('content/ISTD-50.007-Design-Project-Data/CN/dev.in')\n",
        "SGtest = read_data_file('content/ISTD-50.007-Design-Project-Data/SG/dev.in')\n",
        "print('ENtrain:\\n',ENtrain.head())\n",
        "print('ENtest:\\n',ENtest.head())\n",
        "print('CNtrain:\\n',CNtrain.head())\n",
        "print('CNtest:\\n',CNtest.head())\n",
        "print('SGtrain:\\n',SGtrain.head())\n",
        "print('SGtest:\\n',SGtest.head())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excepted ['️'] in content/ISTD-50.007-Design-Project-Data/CN/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/CN/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/CN/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/CN/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/CN/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nexcepted ['️'] in content/ISTD-50.007-Design-Project-Data/SG/dev.in\nENtrain:\n            0       1\n0  Municipal    B-NP\n1      bonds    I-NP\n2        are    B-VP\n3  generally  B-ADVP\n4          a  B-ADJP\nENtest:\n        0\n0    HBO\n1    has\n2  close\n3     to\n4     24\nCNtrain:\n     0  1\n0   【  O\n1  原价  O\n2  12  O\n3   .  O\n4   9  O\nCNtest:\n     0\n0  十年\n1   前\n2  马云\n3  告诉\n4   你\nSGtrain:\n            0          1\n0    Welcome          O\n1      lunch          O\n2        for          O\n3  Charlotte  B-neutral\n4        and          O\nSGtest:\n             0\n0  Everything\n1      sounds\n2      better\n3        with\n4         the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yETvo8UWBL9c",
        "outputId": "b3c09f64-3c97-46f8-b7bb-fa4fc302a452"
      },
      "source": [
        "#Blackmagic\n",
        "print(len('q️q'))\n",
        "print(len('qq'))\n",
        "print('q️q'=='qq')\n",
        "print('magic')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n2\nFalse\nmagic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_nwj8nGfE6"
      },
      "source": [
        "#b_u(O)\n",
        "def get_emission_parameters(dataframe):\n",
        "  states = {}\n",
        "  emission = {}\n",
        "  # to get Count(y)\n",
        "  for row in range(len(dataframe)):\n",
        "    instance = dataframe.iloc[row]\n",
        "    y = str(instance[1])\n",
        "    if not y in states:\n",
        "      states[y] = 1\n",
        "    else:\n",
        "      states[y] += 1\n",
        "  # to get Count(y -> x)\n",
        "  unique_values = dataframe.value_counts().rename_axis(['x', 'y']).reset_index(name='counts')\n",
        "  for row in range(len(unique_values)):\n",
        "    instance = unique_values.iloc[row]\n",
        "    y = str(instance[1])\n",
        "    x = str(instance[0])\n",
        "    key = y+' '+x\n",
        "    count = instance[2]\n",
        "    # obtain count(y) from previous dict\n",
        "    denominator = states[y]\n",
        "    # calculate emission parameter for e(x|y)\n",
        "    emission[key] = count/denominator\n",
        "  # return emission parameters\n",
        "  return emission\n",
        "  \n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cjEXTJSUdWe"
      },
      "source": [
        "#EN_emission = get_emission_parameters(ENtrain)\n",
        "#print(EN_emission)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3fr-ea9cOpS"
      },
      "source": [
        "def get_emission_parameters(dataframe, k):\n",
        "  states = {}\n",
        "  emission = {}\n",
        "  words = {}\n",
        "  # to get Count(y)\n",
        "  for row in range(len(dataframe)):\n",
        "    instance = dataframe.iloc[row]\n",
        "    y = str(instance[1])\n",
        "    if not y in states:\n",
        "      states[y] = 1\n",
        "    else:\n",
        "      states[y] += 1\n",
        "      \n",
        "  # to get Count(y -> x)\n",
        "  unique_values = dataframe.value_counts().rename_axis(['x', 'y']).reset_index(name='counts')\n",
        "  for row in tqdm(range(len(unique_values))):\n",
        "    instance = unique_values.iloc[row]\n",
        "    y = str(instance[1])\n",
        "    x = str(instance[0])\n",
        "    key = y+' '+x\n",
        "    count = instance[2]\n",
        "    unkKey = y+\" #UNK#\"\n",
        "    # obtain count(y) from previous dict\n",
        "    denominator = states[y] + k \n",
        "    # calculate emission parameter for e(x|y)\n",
        "    emission[key] = count/denominator\n",
        "    emission[unkKey] = k/denominator\n",
        "    # save word in words dict so we know what words were in training set\n",
        "    if not x in words:\n",
        "      words[x] = 1\n",
        "    else:\n",
        "      words[x] += 1\n",
        "  # return emission parameters\n",
        "  return emission, states, words"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6fNzqLqetd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95aecc6-ede6-46fb-f624-03873182434a"
      },
      "source": [
        "EN_emission, EN_states, EN_words = get_emission_parameters(ENtrain, 0.5)\r\n",
        "CN_emission, CN_states, CN_words = get_emission_parameters(CNtrain, 0.5)\r\n",
        "SG_emission, SG_states, SG_words = get_emission_parameters(SGtrain, 0.5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25051/25051 [00:03<00:00, 7882.17it/s]\n",
            "100%|██████████| 19867/19867 [00:02<00:00, 7862.03it/s]\n",
            "100%|██████████| 50434/50434 [00:06<00:00, 7983.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbKJAX7tLpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfca4279-f8a5-4431-fd66-d2f58a56d224",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "print(SG_emission)\n",
        "\n",
        "with open('emissiondict', 'w') as f:\n",
        "  f.write(str(SG_emission))\n",
        "#print(EN_emission)\n",
        "#print(EN_states['START'])\n",
        "#print(EN_emission[\"B-NP roadways\"])\n",
        "#print(EN_words)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ps://t.co/66Sqa0h35k': 5.612632914163199e-06, 'O https://t.co/68gy3jMfDh': 5.612632914163199e-06, 'O https://t.co/687JmTyMCS': 5.612632914163199e-06, 'O https://t.co/67z1yDPNXU': 5.612632914163199e-06, 'O https://t.co/67EbxYlXep': 5.612632914163199e-06, 'O https://t.co/66x6rVcij8': 5.612632914163199e-06, 'O https://t.co/66n6c88HmQ': 5.612632914163199e-06, 'O https://t.co/66ZtjxQHmZ': 5.612632914163199e-06, 'O https://t.co/667FgVfbbB': 5.612632914163199e-06, 'O https://t.co/62X9KS1YTj': 5.612632914163199e-06, 'O https://t.co/65d1sQ22VY': 5.612632914163199e-06, 'O https://t.co/653l68AdLk': 5.612632914163199e-06, 'O https://t.co/64jjmZnwoV': 5.612632914163199e-06, 'O https://t.co/64PQt3f2pG': 5.612632914163199e-06, 'O https://t.co/63GFgpzNCw': 5.612632914163199e-06, 'O https://t.co/62xQtpYu3G': 5.612632914163199e-06, 'O https://t.co/62qC1hf6tw': 5.612632914163199e-06, 'O https://t.co/5tBnDmRx5Y': 5.612632914163199e-06, 'O https://t.co/5snmXKWSiV': 5.612632914163199e-06, 'O https://t.co/5seBDSSSll': 5.612632914163199e-06, 'O https://t.co/5hE3rbdo6r': 5.612632914163199e-06, 'O https://t.co/5koWFdko0n': 5.612632914163199e-06, 'O https://t.co/5jW294z0H6': 5.612632914163199e-06, 'O https://t.co/5j293caTKI': 5.612632914163199e-06, 'O https://t.co/5ijOKH4eOV': 5.612632914163199e-06, 'O https://t.co/5icoiaS22g': 5.612632914163199e-06, 'O https://t.co/5hPoG7r7Mu': 5.612632914163199e-06, 'O https://t.co/5hOqPaNshQ': 5.612632914163199e-06, 'O https://t.co/5gEJPAWaeq': 5.612632914163199e-06, 'O https://t.co/5llP4A0EE2': 5.612632914163199e-06, 'O https://t.co/5g9KRHXn4K': 5.612632914163199e-06, 'O https://t.co/5g2Bq1r8ax': 5.612632914163199e-06, 'O https://t.co/5fy5C7vYIz': 5.612632914163199e-06, 'O https://t.co/5fbc8AQllb': 5.612632914163199e-06, 'O https://t.co/5fXyOqrNA0': 5.612632914163199e-06, 'O https://t.co/5f4qTzrHTl': 5.612632914163199e-06, 'O https://t.co/5eva7R4zmC': 5.612632914163199e-06, 'O https://t.co/5l5QAnOljE': 5.612632914163199e-06, 'O https://t.co/5mWa1Cvwbi': 5.612632914163199e-06, 'O https://t.co/5sakbKDqsw': 5.612632914163199e-06, 'O https://t.co/5pw4NpmnjF': 5.612632914163199e-06, 'O https://t.co/5sImmf65tU': 5.612632914163199e-06, 'O https://t.co/5sFVuj2nGM': 5.612632914163199e-06, 'O https://t.co/5qVggv5zaQ': 5.612632914163199e-06, 'O https://t.co/5qS0n9aQVX': 5.612632914163199e-06, 'O https://t.co/5qLmyan1pp': 5.612632914163199e-06, 'O https://t.co/5q9Otr2c6Q': 5.612632914163199e-06, 'O https://t.co/5py1euIruh': 5.612632914163199e-06, 'O https://t.co/5pjV0dS73C': 5.612632914163199e-06, 'O https://t.co/5mkgNh731i': 5.612632914163199e-06, 'O https://t.co/5pP73m7Nnj': 5.612632914163199e-06, 'O https://t.co/5o3LvFHodb': 5.612632914163199e-06, 'O https://t.co/5nvxoYYUlm': 5.612632914163199e-06, 'O https://t.co/5nvkUSZVtM': 5.612632914163199e-06, 'O https://t.co/5nTlkAQTDU': 5.612632914163199e-06, 'O https://t.co/5nIgDXH8M6': 5.612632914163199e-06, 'O https://t.co/5n1Mxu2xhC': 5.612632914163199e-06, 'O https://t.co/77ATHhgvFz': 5.612632914163199e-06, 'O https://t.co/77n4ZFk4Gs': 5.612632914163199e-06, 'O https://t.co/93hIbuvTdc': 5.612632914163199e-06, 'O https://t.co/8PGab6MveQ': 5.612632914163199e-06, 'O https://t.co/8WN2X9vXRf': 5.612632914163199e-06, 'O https://t.co/8VgbLjyfJ6': 5.612632914163199e-06, 'O https://t.co/8VZSBsxZm8': 5.612632914163199e-06, 'O https://t.co/8U5aqFKFUR': 5.612632914163199e-06, 'O https://t.co/8U1o31oFrA': 5.612632914163199e-06, 'O https://t.co/8U0v1MTwk2': 5.612632914163199e-06, 'O https://t.co/8TrNoGyATu': 5.612632914163199e-06, 'O https://t.co/8T95omgpdd': 5.612632914163199e-06, 'O https://t.co/8SuljtlS1D': 5.612632914163199e-06, 'O https://t.co/8Sfw05wE8n': 5.612632914163199e-06, 'O https://t.co/8SfcehCW3z': 5.612632914163199e-06, 'O https://t.co/8ScEJcmypQ': 5.612632914163199e-06, 'O https://t.co/8SYLQ6Jsln': 5.612632914163199e-06, 'O https://t.co/8SLKnIVwEW': 5.612632914163199e-06, 'O https://t.co/8RmtTMI528': 5.612632914163199e-06, 'O https://t.co/8PZts3iXth': 5.612632914163199e-06, 'O https://t.co/8PWtm5eccd': 5.612632914163199e-06, 'O https://t.co/8WhrAAfiXM': 5.612632914163199e-06, 'O https://t.co/8Y1QeDUqH9': 5.612632914163199e-06, 'O https://t.co/8Y8cxj4kI4': 5.612632914163199e-06, 'O https://t.co/8b6LC0Geia': 5.612632914163199e-06, 'O https://t.co/8eRWl4lixK': 5.612632914163199e-06, 'O https://t.co/8eMT7StMJY': 5.612632914163199e-06, 'O https://t.co/8e51jV3aJH': 5.612632914163199e-06, 'O https://t.co/8d30rDWhHo': 5.612632914163199e-06, 'O https://t.co/8cDNRB7ICW': 5.612632914163199e-06, 'O https://t.co/8bW7TuvzpA': 5.612632914163199e-06, 'O https://t.co/8bIDPA9yNJ': 5.612632914163199e-06, 'O https://t.co/8ZyBXtS0Ti': 5.612632914163199e-06, 'O https://t.co/8YC3HBxQRk': 5.612632914163199e-06, 'O https://t.co/8ZrJuqI58M': 5.612632914163199e-06, 'O https://t.co/8ZhDfIboBi': 5.612632914163199e-06, 'O https://t.co/8ZK3Evlud0': 5.612632914163199e-06, 'O https://t.co/8ZI6aXE8NP': 5.612632914163199e-06, 'O https://t.co/8ZGbSx1Ztq': 5.612632914163199e-06, 'O https://t.co/8Yyv9iBRWU': 5.612632914163199e-06, 'O https://t.co/8YUCGwINZq': 5.612632914163199e-06, 'O https://t.co/8PJDPjgUE5': 5.612632914163199e-06, 'O https://t.co/8P9ifQY0IC': 5.612632914163199e-06, 'O https://t.co/8eqyCwUsgr': 5.612632914163199e-06, 'O https://t.co/8P9XTccUu8': 5.612632914163199e-06, 'O https://t.co/8Kn6p1gUbY': 5.612632914163199e-06, 'O https://t.co/8KmiIefwbC': 5.612632914163199e-06, 'O https://t.co/8KeEHCpIXB': 5.612632914163199e-06, 'O https://t.co/8KWSEJcvAL': 5.612632914163199e-06, 'O https://t.co/8Jh0jbgpFy': 5.612632914163199e-06, 'O https://t.co/8JRb7OYE5x': 5.612632914163199e-06, 'O https://t.co/8Ikncp7s1E': 5.612632914163199e-06, 'O https://t.co/8INamHkYCJ': 5.612632914163199e-06, 'O https://t.co/8HNe4C8vic': 5.612632914163199e-06, 'O https://t.co/8GcgxgLv2m': 5.612632914163199e-06, 'O https://t.co/8GDkVU7tqo': 5.612632914163199e-06, 'O https://t.co/8EuYmkZrXt': 5.612632914163199e-06, 'O https://t.co/8EF7IGeJQC': 5.612632914163199e-06, 'O https://t.co/8Dafmwo7o3': 5.612632914163199e-06, 'O https://t.co/8CRs5H3LOu': 5.612632914163199e-06, 'O https://t.co/8CMcvKjm4q': 5.612632914163199e-06, 'O https://t.co/8CEvuFuxtC': 5.612632914163199e-06, 'O https://t.co/8KsMQjGd28': 5.612632914163199e-06, 'O https://t.co/8LGTUOxIJ9': 5.612632914163199e-06, 'O https://t.co/8LXaNgYowc': 5.612632914163199e-06, 'O https://t.co/8NT7lN1lZd': 5.612632914163199e-06, 'O https://t.co/8P5CU6LCUL': 5.612632914163199e-06, 'O https://t.co/8OzBL0VRyX': 5.612632914163199e-06, 'O https://t.co/8OrDnpLL4O': 5.612632914163199e-06, 'O https://t.co/8ObGtSgioY': 5.612632914163199e-06, 'O https://t.co/8NvleYQ2NB': 5.612632914163199e-06, 'O https://t.co/8Nm9UrwZBl': 5.612632914163199e-06, 'O https://t.co/8NfWmSJiIB': 5.612632914163199e-06, 'O https://t.co/8NOL8iSyxz': 5.612632914163199e-06, 'O https://t.co/8LkZTXIlLQ': 5.612632914163199e-06, 'O https://t.co/8NFYUV0Mt9': 5.612632914163199e-06, 'O https://t.co/8N6rwSsnO9': 5.612632914163199e-06, 'O https://t.co/8N3iaPc5IA': 5.612632914163199e-06, 'O https://t.co/8MX6wWO9Ha': 5.612632914163199e-06, 'O https://t.co/8MUirWcPqc': 5.612632914163199e-06, 'O https://t.co/8M8y5ola5q': 5.612632914163199e-06, 'O https://t.co/8M0W2qYgjP': 5.612632914163199e-06, 'O https://t.co/8em3M9qMMv': 5.612632914163199e-06, 'O https://t.co/8fBu2KLAy7': 5.612632914163199e-06, 'O https://t.co/78S76U1h28': 5.612632914163199e-06, 'O https://t.co/8s5QIzVoF7': 5.612632914163199e-06, 'O https://t.co/8y10Rcdrah': 5.612632914163199e-06, 'O https://t.co/8xuJx1rJ9w': 5.612632914163199e-06, 'O https://t.co/8xtKsPfY1t': 5.612632914163199e-06, 'O https://t.co/8xil6lvNa8': 5.612632914163199e-06, 'O https://t.co/8x9Gksdv28': 5.612632914163199e-06, 'O https://t.co/8wyxzTg54S': 5.612632914163199e-06, 'O https://t.co/8wVM9WNsai': 5.612632914163199e-06, 'O https://t.co/8votmcuTkZ': 5.612632914163199e-06, 'O https://t.co/8veizRnQX0': 5.612632914163199e-06, 'O https://t.co/8vYqb8a30R': 5.612632914163199e-06, 'O https://t.co/8v6semVutN': 5.612632914163199e-06, 'O https://t.co/8v5KME2xvC': 5.612632914163199e-06, 'O https://t.co/8ud3CwKdnJ': 5.612632914163199e-06, 'O https://t.co/8u6jktb7bA': 5.612632914163199e-06, 'O https://t.co/8tuLCWBwgf': 5.612632914163199e-06, 'O https://t.co/8thZkXr7ZX': 5.612632914163199e-06, 'O https://t.co/8tRQQCz8Yn': 5.612632914163199e-06, 'O https://t.co/8zStALS5NG': 5.612632914163199e-06, 'O https://t.co/8za4steA4J': 5.612632914163199e-06, 'O https://t.co/8zdd1gbBn3': 5.612632914163199e-06, 'O https://t.co/91UQfYXy9J': 5.612632914163199e-06, 'O https://t.co/93gGU5JNC8': 5.612632914163199e-06, 'O https://t.co/93bUs8gG9d': 5.612632914163199e-06, 'O https://t.co/93FYHkOTXK': 5.612632914163199e-06, 'O https://t.co/92riPn9C75': 5.612632914163199e-06, 'O https://t.co/92r7uWp9SE': 5.612632914163199e-06, 'O https://t.co/92cwWUVSKW': 5.612632914163199e-06, 'O https://t.co/922gDxEJqi': 5.612632914163199e-06, 'O https://t.co/91FmNy3ZJJ': 5.612632914163199e-06, 'O https://t.co/8zdw6TId67': 5.612632914163199e-06, 'O https://t.co/90fUBVNAeJ': 5.612632914163199e-06, 'O https://t.co/90ayW1qxhy': 5.612632914163199e-06, 'O https://t.co/90VyKONdBZ': 5.612632914163199e-06, 'O https://t.co/90OTkaiyC3': 5.612632914163199e-06, 'O https://t.co/90Ax8Q6k8I': 5.612632914163199e-06, 'O https://t.co/908Vctdq8D': 5.612632914163199e-06, 'O https://t.co/8zeUvOYQpe': 5.612632914163199e-06, 'O https://t.co/8soVgQGhdl': 5.612632914163199e-06, 'O https://t.co/8rzSfgKWU4': 5.612632914163199e-06, 'O https://t.co/8fQcgVFHLG': 5.612632914163199e-06, 'O https://t.co/8rq6l3qvKF': 5.612632914163199e-06, 'O https://t.co/8m9QWLNzwo': 5.612632914163199e-06, 'O https://t.co/8m3HwSVZ9A': 5.612632914163199e-06, 'O https://t.co/8laYJm7FDJ': 5.612632914163199e-06, 'O https://t.co/8lNMqiO8jn': 5.612632914163199e-06, 'O https://t.co/8lKkCjdMj3': 5.612632914163199e-06, 'O https://t.co/8lFJp2bcBh': 5.612632914163199e-06, 'O https://t.co/8l0Zz3aRMB': 5.612632914163199e-06, 'O https://t.co/8kHBfc1zAo': 5.612632914163199e-06, 'O https://t.co/8k7PGOLcfW': 5.612632914163199e-06, 'O https://t.co/8k7E5AjUjn': 5.612632914163199e-06, 'O https://t.co/8iLvtUFDR9': 5.612632914163199e-06, 'O https://t.co/8iCl7LEke6': 5.612632914163199e-06, 'O https://t.co/8iBc1KRiUL': 5.612632914163199e-06, 'O https://t.co/8hZtAO0ahK': 5.612632914163199e-06, 'O https://t.co/8gmTd33K7X': 5.612632914163199e-06, 'O https://t.co/8gWzl5JNat': 5.612632914163199e-06, 'O https://t.co/8fwogHLh9U': 5.612632914163199e-06, 'O https://t.co/8mb0PWjFCL': 5.612632914163199e-06, 'O https://t.co/8mvnGf5EV5': 5.612632914163199e-06, 'O https://t.co/8nSX6lDa9v': 5.612632914163199e-06, 'O https://t.co/8p695VqtQS': 5.612632914163199e-06, 'O https://t.co/8rlE9sw3dw': 5.612632914163199e-06, 'O https://t.co/8rixDIdg9C': 5.612632914163199e-06, 'O https://t.co/8rd9imBySG': 5.612632914163199e-06, 'O https://t.co/8rCNgsKmfP': 5.612632914163199e-06, 'O https://t.co/8qlorSo35h': 5.612632914163199e-06, 'O https://t.co/8qGKuYygBx': 5.612632914163199e-06, 'O https://t.co/8qA6DDr7vY': 5.612632914163199e-06, 'O https://t.co/8opQefqYcJ': 5.612632914163199e-06, 'O https://t.co/8nV8KYPeDy': 5.612632914163199e-06, 'O https://t.co/8okIiD6R2A': 5.612632914163199e-06, 'O https://t.co/8oXF7LPXRn': 5.612632914163199e-06, 'O https://t.co/8oTe58MWUw': 5.612632914163199e-06, 'O https://t.co/8oL1uaLXTZ': 5.612632914163199e-06, 'O https://t.co/8oB37Yaznq': 5.612632914163199e-06, 'O https://t.co/8o4Ppj7L8q': 5.612632914163199e-06, 'O https://t.co/8o2RKYnJa4': 5.612632914163199e-06, 'O https://t.co/8BxO5nJyoH': 5.612632914163199e-06, 'O https://t.co/8Bx6J72GNR': 5.612632914163199e-06, 'O https://t.co/8BdEYQZ1B1': 5.612632914163199e-06, 'O https://t.co/7LbqFvmZAk': 5.612632914163199e-06, 'O https://t.co/7TJICTAqUN': 5.612632914163199e-06, 'O https://t.co/7THbeDd6wR': 5.612632914163199e-06, 'O https://t.co/7Se4znZDGE': 5.612632914163199e-06, 'O https://t.co/7Rl1Afg2wN': 5.612632914163199e-06, 'O https://t.co/7QsTnxzPvM': 5.612632914163199e-06, 'O https://t.co/7QilMF2GBr': 5.612632914163199e-06, 'O https://t.co/7QI7NMYHpF': 5.612632914163199e-06, 'O https://t.co/7Q8KDxxR3v': 5.612632914163199e-06, 'O https://t.co/7Pxyh4KyEn': 5.612632914163199e-06, 'O https://t.co/7PbDRkf7xz': 5.612632914163199e-06, 'O https://t.co/7Oq7Vlcneq': 5.612632914163199e-06, 'O https://t.co/7NKfcy6GnR': 5.612632914163199e-06, 'O https://t.co/7NIgPObQyn': 5.612632914163199e-06, 'O https://t.co/7N41EqYk9u': 5.612632914163199e-06, 'O https://t.co/7Mm3MGoCUR': 5.612632914163199e-06, 'O https://t.co/7MJA16SqJT': 5.612632914163199e-06, 'O https://t.co/7LurhPYfMR': 5.612632914163199e-06, 'O https://t.co/7TXFlZ3Skj': 5.612632914163199e-06, 'O https://t.co/7TuaobOKga': 5.612632914163199e-06, 'O https://t.co/7UVkM4wRNf': 5.612632914163199e-06, 'O https://t.co/7ZerWg78B3': 5.612632914163199e-06, 'O https://t.co/7fMSEo3ySJ': 5.612632914163199e-06, 'O https://t.co/7fHjaOHmAH': 5.612632914163199e-06, 'O https://t.co/7coS6013Rk': 5.612632914163199e-06, 'O https://t.co/7cc4XTC2Zn': 5.612632914163199e-06, 'O https://t.co/7cAT8kzoh6': 5.612632914163199e-06, 'O https://t.co/7aKmPjPJzD': 5.612632914163199e-06, 'O https://t.co/7a5t8yIxfP': 5.612632914163199e-06, 'O https://t.co/7Z7Ybe2EQQ': 5.612632914163199e-06, 'O https://t.co/7V73vDd0c5': 5.612632914163199e-06, 'O https://t.co/7YqRegSfhD': 5.612632914163199e-06, 'O https://t.co/7YPvTWEqtR': 5.612632914163199e-06, 'O https://t.co/7YJ2HHEdSf': 5.612632914163199e-06, 'O https://t.co/7Xvcu0GoSr': 5.612632914163199e-06, 'O https://t.co/7XVmJ72JIV': 5.612632914163199e-06, 'O https://t.co/7WoSbQbCtA': 5.612632914163199e-06, 'O https://t.co/7VjcFYUXbZ': 5.612632914163199e-06, 'O https://t.co/7LsC9ZHEak': 5.612632914163199e-06, 'O https://t.co/7LbKBr8b54': 5.612632914163199e-06, 'O https://t.co/8BSY7lnReX': 5.612632914163199e-06, 'O https://t.co/7LEaYJUSye': 5.612632914163199e-06, 'O https://t.co/7CrLMx8SH0': 5.612632914163199e-06, 'O https://t.co/7Cm6ROgx1J': 5.612632914163199e-06, 'O https://t.co/7Bqx43fBVh': 5.612632914163199e-06, 'O https://t.co/7BbmGdsOyB': 5.612632914163199e-06, 'O https://t.co/7BOvSA0yiJ': 5.612632914163199e-06, 'O https://t.co/7BIkfO0Ab7': 5.612632914163199e-06, 'O https://t.co/7BAE2MeA8k': 5.612632914163199e-06, 'O https://t.co/7Az2bRqPXv': 5.612632914163199e-06, 'O https://t.co/7AqsRpq554': 5.612632914163199e-06, 'O https://t.co/7AJq2G8fdM': 5.612632914163199e-06, 'O https://t.co/79ZxvTQHPz': 5.612632914163199e-06, 'O https://t.co/79W5N4fZ0K': 5.612632914163199e-06, 'O https://t.co/79TqNv78bc': 5.612632914163199e-06, 'O https://t.co/79OXcqOl3k': 5.612632914163199e-06, 'O https://t.co/792mrXnvHt': 5.612632914163199e-06, 'O https://t.co/78zJIlCa3w': 5.612632914163199e-06, 'O https://t.co/78t2Yy72iZ': 5.612632914163199e-06, 'O https://t.co/7CxyliwMFE': 5.612632914163199e-06, 'O https://t.co/7D0gdzPuDg': 5.612632914163199e-06, 'O https://t.co/7DDaXi0g5x': 5.612632914163199e-06, 'O https://t.co/7HydxsHflQ': 5.612632914163199e-06, 'O https://t.co/7KyocAOinp': 5.612632914163199e-06, 'O https://t.co/7KhYjcBykJ': 5.612632914163199e-06, 'O https://t.co/7KA3P2wvyR': 5.612632914163199e-06, 'O https://t.co/7JZKDpjmqP': 5.612632914163199e-06, 'O https://t.co/7JQb4jAkh8': 5.612632914163199e-06, 'O https://t.co/7I8nGlsF9o': 5.612632914163199e-06, 'O https://t.co/7I4dq4gwFk': 5.612632914163199e-06, 'O https://t.co/7HxEmm1NE9': 5.612632914163199e-06, 'O https://t.co/7E33YnDgbh': 5.612632914163199e-06, 'O https://t.co/7GQo0jqCoZ': 5.612632914163199e-06, 'O https://t.co/7GLIQADqcl': 5.612632914163199e-06, 'O https://t.co/7G0h9oKhBr': 5.612632914163199e-06, 'O https://t.co/7FmRpVwDuh': 5.612632914163199e-06, 'O https://t.co/7FjsyshlHB': 5.612632914163199e-06, 'O https://t.co/7FHhTjDxRx': 5.612632914163199e-06, 'O https://t.co/7EcHhAR0Pq': 5.612632914163199e-06, 'O https://t.co/7g5ZZ0k1cV': 5.612632914163199e-06, 'O https://t.co/7gKFT6vEuq': 5.612632914163199e-06, 'O https://t.co/7gb6Um6HlF': 5.612632914163199e-06, 'O https://t.co/7gyNiKeCkZ': 5.612632914163199e-06, 'O https://t.co/82qXSWx3n6': 5.612632914163199e-06, 'O https://t.co/82OO72Uz3X': 5.612632914163199e-06, 'O https://t.co/81w3MdVYA8': 5.612632914163199e-06, 'O https://t.co/817dsEiSJi': 5.612632914163199e-06, 'O https://t.co/817YfKrC48': 5.612632914163199e-06, 'O https://t.co/80g8fnQ0rN': 5.612632914163199e-06, 'O https://t.co/80GKnTgq4h': 5.612632914163199e-06, 'O https://t.co/80CbwM8iyg': 5.612632914163199e-06, 'O https://t.co/800aH1CMK8': 5.612632914163199e-06, 'O https://t.co/7zjDZJi0Sl': 5.612632914163199e-06, 'O https://t.co/7ziqLhCNbv': 5.612632914163199e-06, 'O https://t.co/7y7upqucVG': 5.612632914163199e-06, 'O https://t.co/7xyvMwor8v': 5.612632914163199e-06, 'O https://t.co/7xiVoRcBtB': 5.612632914163199e-06, 'O https://t.co/7xIWry0JY1': 5.612632914163199e-06, 'O https://t.co/7xBrJ2VJWb': 5.612632914163199e-06, 'O https://t.co/7wltow21ct': 5.612632914163199e-06, 'O https://t.co/83NvsVrGwR': 5.612632914163199e-06, 'O https://t.co/83Xe0UjOBt': 5.612632914163199e-06, 'O https://t.co/844F0RCru6': 5.612632914163199e-06, 'O https://t.co/86t8aX3VzR': 5.612632914163199e-06, 'O https://t.co/89nAVtpkL9': 5.612632914163199e-06, 'O https://t.co/89OsvWcKRl': 5.612632914163199e-06, 'O https://t.co/88pTcRsy6U': 5.612632914163199e-06, 'O https://t.co/88a1EVKqeA': 5.612632914163199e-06, 'O https://t.co/87RL5vffIY': 5.612632914163199e-06, 'O https://t.co/87R5es1MHe': 5.612632914163199e-06, 'O https://t.co/870mtLKsZr': 5.612632914163199e-06, 'O https://t.co/86lRBZFZje': 5.612632914163199e-06, 'O https://t.co/84EwnUJGmS': 5.612632914163199e-06, 'O https://t.co/86azzh96wK': 5.612632914163199e-06, 'O https://t.co/86IClaVXMH': 5.612632914163199e-06, 'O https://t.co/86IC6erhef': 5.612632914163199e-06, 'O https://t.co/85xSi3Xn33': 5.612632914163199e-06, 'O https://t.co/85ZaYCPkE8': 5.612632914163199e-06, 'O https://t.co/85S7pSCwf4': 5.612632914163199e-06, 'O https://t.co/85FmaWJGnI': 5.612632914163199e-06, 'O https://t.co/7w9bar4Mx1': 5.612632914163199e-06, 'O https://t.co/7vTGI50kUY': 5.612632914163199e-06, 'O https://t.co/7v5FVEdCr9': 5.612632914163199e-06, 'O https://t.co/7kOGs3PduD': 5.612632914163199e-06, 'O https://t.co/7nQf9Ce8Hg': 5.612632914163199e-06, 'O https://t.co/7mB6kADTlE': 5.612632914163199e-06, 'O https://t.co/7ly9L9z8tX': 5.612632914163199e-06, 'O https://t.co/7lqWyErlMq': 5.612632914163199e-06, 'O https://t.co/7laPsYOvJ8': 5.612632914163199e-06, 'O https://t.co/7lM9aTgqqs': 5.612632914163199e-06, 'O https://t.co/7lLcTPfOpS': 5.612632914163199e-06, 'O https://t.co/7kFcLmWZy4': 5.612632914163199e-06, 'O https://t.co/7oNhHOd1MP': 5.612632914163199e-06, 'O https://t.co/7kDBUxT5fk': 5.612632914163199e-06, 'O https://t.co/7jZb3SBon1': 5.612632914163199e-06, 'O https://t.co/7iuo7IiNEv': 5.612632914163199e-06, 'O https://t.co/7id5zD6wk2': 5.612632914163199e-06, 'O https://t.co/7icMHISrfR': 5.612632914163199e-06, 'O https://t.co/7iHL01T3cQ': 5.612632914163199e-06, 'O https://t.co/7hnIiNmARS': 5.612632914163199e-06, 'O https://t.co/7nfMLcrTtK': 5.612632914163199e-06, 'O https://t.co/7oXzi678L3': 5.612632914163199e-06, 'O https://t.co/7uyaoDQQm4': 5.612632914163199e-06, 'O https://t.co/7tLUZWBDzq': 5.612632914163199e-06, 'O https://t.co/7uw61qgfrO': 5.612632914163199e-06, 'O https://t.co/7unyCWonXH': 5.612632914163199e-06, 'O https://t.co/7ujAS2xFFJ': 5.612632914163199e-06, 'O https://t.co/7uLj01OW6M': 5.612632914163199e-06, 'O https://t.co/7tvu53Hrfk': 5.612632914163199e-06, 'O https://t.co/7tiVx4TAZV': 5.612632914163199e-06, 'O https://t.co/7tMgyDGicI': 5.612632914163199e-06, 'O https://t.co/7t5v5X2oV5': 5.612632914163199e-06, 'O https://t.co/7ot1gAXzSw': 5.612632914163199e-06, 'O https://t.co/7siJRF34aj': 5.612632914163199e-06, 'O https://t.co/7qtjoJ341C': 5.612632914163199e-06, 'O https://t.co/7q0DXIuxpm': 5.612632914163199e-06, 'O https://t.co/7pxSo90yyu': 5.612632914163199e-06, 'O https://t.co/7pralygJ9b': 5.612632914163199e-06, 'O https://t.co/7pWeTshjgy': 5.612632914163199e-06, 'O https://t.co/7pPSQqUW2n': 5.612632914163199e-06, 'B-neutral !': 4.021151255604479e-05}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeEncodeError",
          "evalue": "'charmap' codec can't encode character '\\u2764' in position 2917: character maps to <undefined>",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-38-a0a0a39b93aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emissiondict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSG_emission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(EN_emission)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#print(EN_states['START'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u2764' in position 2917: character maps to <undefined>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lr-23_mkJ8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849ec03a-1985-4b99-df06-7fa132efd1ae"
      },
      "source": [
        "def get_max_y(x,dd):\n",
        "  maxP = 0\n",
        "  maxY = ''\n",
        "  mUNKP = 0\n",
        "  mUNKY = ''\n",
        "  for i in dd.keys():\n",
        "    mykey = i.split(' ')\n",
        "    if mykey[1] == \"#UNK#\":\n",
        "      cUNKP = dd[i]\n",
        "      cUNKY = mykey[0]\n",
        "      if cUNKP>mUNKP:\n",
        "        mUNKP = cUNKP\n",
        "        mUNKY = cUNKY\n",
        "    if x == mykey[1]: #[y,x] if x in\n",
        "      currentP = dd[i]\n",
        "      currentY = mykey[0]\n",
        "      if currentP>maxP:\n",
        "        maxP = currentP\n",
        "        maxY = currentY\n",
        "      else:\n",
        "        continue\n",
        "  if maxY == '' and maxP == 0:\n",
        "    maxY = mUNKY\n",
        "\n",
        "  return maxY\n",
        "\n",
        "def label_data(df,dd):\n",
        "  labels = []\n",
        "  for row in tqdm(range(len(df))):\n",
        "    x = str(df.iloc[row][0])\n",
        "    y = get_max_y(x,dd)\n",
        "    labels.append(y)\n",
        "  df[1] = labels\n",
        "  return df\n",
        "\n",
        "CNdf = label_data(CNtest, CN_emission)\n",
        "ENdf = label_data(ENtest, EN_emission)\n",
        "SGdf = label_data(SGtest, SG_emission)\n",
        "def write_to_file(df,file_loc):\n",
        "  with open(file_loc,'w') as f:\n",
        "    for row in tqdm(range(len(df))):\n",
        "      x = str(df.iloc[row][0])+' '+str(df.iloc[row][1])+'\\n'\n",
        "      f.write(x)\n",
        "  f.close()\n",
        "\n",
        "#write_to_file(CNdf,'content/ISTD-50.007-Design-Project-Data/CN/dev.p2.out')\n",
        "#write_to_file(ENdf,'content/ISTD-50.007-Design-Project-Data/EN/dev.p2.out')\n",
        "write_to_file(SGdf,'content/ISTD-50.007-Design-Project-Data/SG/dev.p2.out')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ9PYMgHxIuj"
      },
      "source": [
        "print(\"English\")\n",
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p2.out\n",
        "print(\"Chineeese\")\n",
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/CN/dev.out ISTD-50.007-Design-Project-Data/CN/dev.p2.out\n",
        "print(\"Singha\")\n",
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p2.out\n",
        "\n",
        "#!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EvalScript/dev.out ISTD-50.007-Design-Project-Data/EvalScript/dev.prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs920If40FCl"
      },
      "source": [
        "Part 3: MLE Transition Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7IbkZng0SCz"
      },
      "source": [
        "def read_training_file(file):\n",
        "  with open(file,'r') as f:\n",
        "    ls = []\n",
        "    START = [None, 'START']\n",
        "    STOP = [None, 'STOP']\n",
        "    ls.append(START)\n",
        "    for line in f.readlines():\n",
        "      if line == '\\n':\n",
        "        ls.append(STOP)\n",
        "        ls.append(START)\n",
        "      else:\n",
        "        #ls.append(line.strip().split(' ')) # DOSENT INPUT #SPACE#\n",
        "        ls1 = line.strip().split(' ')\n",
        "        test_str = 'q'+ls1[0]+'q'\n",
        "        if test_str == 'q️q': #pls dont delete invisible char here\n",
        "          #print(file_loc,ls)\n",
        "          try:\n",
        "            ls2 = ['#SPACE#', ls1[1]]\n",
        "            ls.append(ls2)\n",
        "          except:\n",
        "            print(f'excepted {ls1} in {file}')\n",
        "        else:\n",
        "          ls.append(ls1)\n",
        "    ls.pop()\n",
        "  return ls\n",
        "\n",
        "def read_test_file(file):\n",
        "  count = 0\n",
        "  with open(file,'r') as f:\n",
        "    ls = []\n",
        "    START = '###START###'\n",
        "    STOP = '###STOP###'\n",
        "    ls.append(START)\n",
        "    for line in f.readlines():\n",
        "      count+=1\n",
        "      if line == '\\n':\n",
        "        ls.append(STOP)\n",
        "        ls.append(START)\n",
        "      else:\n",
        "        app_str = line.strip()\n",
        "        if 'q'+app_str+'q' == 'q️q':\n",
        "          print(repr(app_str))\n",
        "          #print(count)\n",
        "          ls.append(\"#SPACE#\")\n",
        "        else:\n",
        "          ls.append(app_str)\n",
        "    ls.pop()\n",
        "  return ls\n",
        "\n",
        "def get_transition_parameters(ls):\n",
        "  arra_y = [i[1] for i in ls]\n",
        "  states = {}\n",
        "  yoyi_count = {}\n",
        "  transition = {}\n",
        "  # to get Count(y)\n",
        "  pervy = 'STOP'\n",
        "  curry = ''\n",
        "  for y in arra_y:\n",
        "    curry = y\n",
        "    if not y in states:\n",
        "      states[y] = 1\n",
        "    else:\n",
        "      states[y] += 1\n",
        "    # to get count(y0 -> y1)\n",
        "    yoyi = pervy+' '+curry\n",
        "    if not yoyi in yoyi_count:\n",
        "      yoyi_count[yoyi] = 1\n",
        "    else:\n",
        "      yoyi_count[yoyi] += 1\n",
        "    pervy = y\n",
        "  # calculate transition parameters\n",
        "  for i,n in yoyi_count.items():\n",
        "    y0 = i.split(' ')[0]\n",
        "    # ignore all state transitions of STOP -> y1\n",
        "    if y0 == 'STOP':\n",
        "      continue\n",
        "    transition[i] = n/states[y0]\n",
        "  return transition\n",
        "\n",
        "\n",
        "#print(ENtrain)\n",
        "#dip_shit = read_training_file('/content/ISTD-50.007-Design-Project-Data/EN/train')\n",
        "#print(dip_shit[40:75])\n",
        "dip_shits = read_training_file('content/ISTD-50.007-Design-Project-Data/SG/train')\n",
        "print(dip_shits[50:80],'\\n')\n",
        "dev_in = read_test_file('content/ISTD-50.007-Design-Project-Data/SG/dev.in')\n",
        "print(dev_in[80:100])\n",
        "print(len('q️q'))\n",
        "#dip_shite = read_training_file('/content/ISTD-50.007-Design-Project-Data/CN/train')\n",
        "#print(dip_shit[2:4])\n",
        "\n",
        "\n",
        "CN_transitions = get_transition_parameters(dip_shite)\n",
        "#print(EN_transitions['B-VP I-NP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00MQiw2aefnB"
      },
      "source": [
        "#dev_in = read_test_file('/content/ISTD-50.007-Design-Project-Data/EN/dev.in')\n",
        "dev_in = read_test_file('content/ISTD-50.007-Design-Project-Data/CN/dev.in')\n",
        "#print(dev_in[-2])\n",
        "\n",
        "\n",
        "class viterbi:\n",
        "\n",
        "  def __init__(self,transitions, emission, states, words, testdata):\n",
        "    self.PROB_MULTIPLIER = 1\n",
        "    self.transitions = transitions\n",
        "    self.emission = emission\n",
        "    ls = list(states.keys())\n",
        "    ls.insert(0, 'START')\n",
        "    ls.append('STOP')\n",
        "    self.all_states = ls\n",
        "    self.testdata = testdata\n",
        "    self.sentence = []\n",
        "    self.words = words\n",
        "    self.predictions = []\n",
        "\n",
        "  def get_predictions(self):\n",
        "    return self.predictions\n",
        "\n",
        "  def test_file_to_sentences(self,testdata):\n",
        "    ls = []\n",
        "    sentences = []\n",
        "    for i in testdata:\n",
        "      if i != '###START###' and i != \"###STOP###\":\n",
        "        ls.append(i)\n",
        "      if i == '###STOP###':\n",
        "        sentences.append(ls)\n",
        "        ls = []\n",
        "    return sentences\n",
        "\n",
        "  def pi(self,layer, current_state_pointer, score_matrix):\n",
        "    mul = self.PROB_MULTIPLIER\n",
        "    sentence = self.sentence\n",
        "    words = self.words\n",
        "    states = self.all_states\n",
        "    current_state = states[current_state_pointer]\n",
        "    # initialization (START layer)\n",
        "    if layer == 0:\n",
        "      if current_state == \"START\":\n",
        "        return 1\n",
        "      else :\n",
        "        return 0\n",
        "    # final step (STOP layer)\n",
        "    elif layer == len(sentence)+1:\n",
        "      ls1 = []\n",
        "      if current_state == \"STOP\":\n",
        "        for i in range(len(states)):\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix[layer-1,i]):\n",
        "            ls1.append(self.pi(layer-1,i)*a)\n",
        "          else:\n",
        "            ls1.append(score_matrix[layer-1,i]*a)\n",
        "        return max(ls1)\n",
        "      else:\n",
        "        return 0\n",
        "    # middle layers (for each word in the sentence)\n",
        "    else:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return 0\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:\n",
        "              b = 0\n",
        "          else:\n",
        "            b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix[layer-1,i]*a*b)\n",
        "      return max(ls)\n",
        "\n",
        "  def viterbi_sentence(self,sentence_testdata):\n",
        "    no_route = None\n",
        "    states = self.all_states\n",
        "    self.sentence = sentence_testdata\n",
        "    sentence = self.sentence\n",
        "    # create empty score matrix to store all pi values\n",
        "    score_matrix = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix[:] = np.NaN\n",
        "    # empty list to store predicted labels\n",
        "    pred_label = []\n",
        "    # viterbi algorithm\n",
        "    for j in range(len(sentence)+2):\n",
        "      for u in range(len(states)):\n",
        "        score = self.pi(j,u, score_matrix)\n",
        "        score_matrix[j,u] = score\n",
        "        #print(\"State: \", self.all_states[u])\n",
        "        #print(\"Score:\",score)\n",
        "      if max(score_matrix[j])==0 and no_route==None:\n",
        "        #print(j-1)\n",
        "        no_route = j-1\n",
        "    # backtracking\n",
        "    previous_max_y = 'STOP'\n",
        "    for j in range(len(sentence)+1,0,-1):\n",
        "      # ignore STOP layer\n",
        "      if j == len(sentence)+1:\n",
        "        continue\n",
        "      score_dd = {}\n",
        "      if max(score_matrix[j])==0:\n",
        "        pred_label.insert(0, random.choice(states[1:-2]))\n",
        "      else:\n",
        "        for u in range(len(states)):\n",
        "          score = score_matrix[j,u]\n",
        "          try:\n",
        "            a = self.transitions[states[u]+' '+previous_max_y]\n",
        "          except:\n",
        "            a = 0\n",
        "          score_dd[states[u]] = score*a\n",
        "        previous_max_y = max(score_dd, key=score_dd.get)\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "        #print(pred_label)\n",
        "    return pred_label\n",
        "\n",
        "  def run(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    with open ('content/ISTD-50.007-Design-Project-Data/CN/dev.p3.out', 'w') as f:\n",
        "      for i in tqdm(self.sentences):\n",
        "        self.predicted_labels = self.viterbi_sentence(i)\n",
        "        self.predictions.append(self.predicted_labels)\n",
        "        tuplelist = [(i[l], self.predicted_labels[l]) for l in range(len(i))]\n",
        "        for (x, y) in tuplelist:\n",
        "          f.write(x+\" \"+y+\"\\n\")\n",
        "        f.write('\\n')\n",
        "\n",
        "  def runone(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    print(self.sentences[4])\n",
        "    self.predicted_labels = self.viterbi_sentence(self.sentences[4])\n",
        "\n",
        "\n",
        "#balls = viterbi(EN_transitions, EN_emission,EN_states,EN_words,dev_in)\n",
        "balls = viterbi(CN_transitions, CN_emission,CN_states,CN_words,dev_in)\n",
        "balls.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5K-DuBir5Z3"
      },
      "source": [
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p3.out\r\n",
        "print(\"Chinese\")\r\n",
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/CN/dev.out ISTD-50.007-Design-Project-Data/CN/dev.p3.out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMNR9j6uCUO"
      },
      "source": [
        "Part 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGCcvBLwuEr9"
      },
      "source": [
        "dev_in = read_test_file('content/ISTD-50.007-Design-Project-Data/EN/dev.in')\n",
        "#print(dev_in[-2])\n",
        "\n",
        "\n",
        "class viterbi:\n",
        "\n",
        "  def __init__(self,transitions, emission, states, words, testdata):\n",
        "    self.PROB_MULTIPLIER = 1\n",
        "    self.transitions = transitions\n",
        "    self.emission = emission\n",
        "    ls = list(states.keys())\n",
        "    ls.insert(0, 'START')\n",
        "    ls.append('STOP')\n",
        "    self.all_states = ls\n",
        "    self.testdata = testdata\n",
        "    self.sentence = []\n",
        "    self.words = words\n",
        "    self.predictions = []\n",
        "\n",
        "  def get_predictions(self):\n",
        "    return self.predictions\n",
        "\n",
        "  def test_file_to_sentences(self,testdata):\n",
        "    ls = []\n",
        "    sentences = []\n",
        "    for i in testdata:\n",
        "      if i != '###START###' and i != \"###STOP###\":\n",
        "        ls.append(i)\n",
        "      if i == '###STOP###':\n",
        "        sentences.append(ls)\n",
        "        ls = []\n",
        "    return sentences\n",
        "\n",
        "  def pi(self,layer, current_state_pointer, score_matrix1,score_matrix2, score_matrix3):\n",
        "    mul = self.PROB_MULTIPLIER\n",
        "    sentence = self.sentence\n",
        "    words = self.words\n",
        "    states = self.all_states\n",
        "    current_state = states[current_state_pointer]\n",
        "    # initialization (START layer)\n",
        "    if layer == 0:\n",
        "      if current_state == \"START\":\n",
        "        return [1,1,1]\n",
        "      else :\n",
        "        return [0,0,0]\n",
        "    # final step (STOP layer)\n",
        "    # need to loop all the parts that use score_matrix, so that we calculate for all score matrices\n",
        "    elif layer == len(sentence)+1:\n",
        "      ls1 = []\n",
        "      if current_state == \"STOP\":\n",
        "        for i in range(len(states)):\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          # first matrix\n",
        "          if np.isnan(score_matrix1[layer-1,i]):\n",
        "            ls1.append(self.pi(layer-1,i)*a)\n",
        "          else:\n",
        "            ls1.append(score_matrix1[layer-1,i]*a)\n",
        "          # second matrix\n",
        "          if np.isnan(score_matrix2[layer-1,i]):\n",
        "            ls1.append(self.pi(layer-1,i)*a)\n",
        "          else:\n",
        "            ls1.append(score_matrix2[layer-1,i]*a)\n",
        "          # third matrix\n",
        "          if np.isnan(score_matrix3[layer-1,i]):\n",
        "            ls1.append(self.pi(layer-1,i)*a)\n",
        "          else:\n",
        "            ls1.append(score_matrix3[layer-1,i]*a)\n",
        "        # sort the ls1 in descending order\n",
        "        ls1.sort(reverse=True)\n",
        "        return ls1[:3]\n",
        "      else:\n",
        "        return [0,0,0]\n",
        "    elif layer==1:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return [0, 0, 0]\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:\n",
        "              b = 0\n",
        "          else:\n",
        "            b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix1[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix1[layer-1,i]*a*b)\n",
        "      return [max(ls), 0, 0]\n",
        "    # middle layers (for each word in the sentence)\n",
        "    # need to loop all the parts that use score_matrix, so that we calculate for all score matrices\n",
        "    else:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return [0,0,0]\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:\n",
        "              b = 0\n",
        "          else:\n",
        "            b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          # first matrix\n",
        "          if np.isnan(score_matrix1[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix1[layer-1,i]*a*b)\n",
        "          # second matrix\n",
        "          if np.isnan(score_matrix2[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix2[layer-1,i]*a*b)\n",
        "          # third matrix\n",
        "          if np.isnan(score_matrix3[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix3[layer-1,i]*a*b)\n",
        "      # sort the ls in descending order\n",
        "      ls.sort(reverse=True) \n",
        "      return ls[:3]\n",
        "\n",
        "  def viterbi_sentence(self,sentence_testdata):\n",
        "    no_route = None\n",
        "    states = self.all_states\n",
        "    self.sentence = sentence_testdata\n",
        "    sentence = self.sentence\n",
        "    # create 3 empty score matrix to store top 3 pi values\n",
        "    score_matrix1 = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix1[:] = np.NaN\n",
        "\n",
        "    score_matrix2 = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix2[:] = np.NaN\n",
        "\n",
        "    score_matrix3 = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix3[:] = np.NaN\n",
        "    # empty list to store predicted labels\n",
        "    pred_label = []\n",
        "    # viterbi algorithm\n",
        "    for j in range(len(sentence)+2):\n",
        "      for u in range(len(states)):\n",
        "        # scores is a list of top 3 values\n",
        "        scores = self.pi(j,u, score_matrix1, score_matrix2, score_matrix3)\n",
        "        score_matrix1[j,u] = scores[0]\n",
        "        score_matrix2[j,u] = scores[1]\n",
        "        score_matrix3[j,u] = scores[2]\n",
        "        #print(\"State: \", self.all_states[u])\n",
        "        #print(\"Score:\",scores)\n",
        "    \"\"\"\n",
        "    print(\"1:\",score_matrix1)\n",
        "    print(\"2:\",score_matrix2)\n",
        "    print(\"3:\",score_matrix3)\n",
        "    \"\"\"\n",
        "    # backtracking\n",
        "    previous_max_y = 'STOP'\n",
        "    for j in range(len(sentence)+1,0,-1):\n",
        "      # ignore STOP layer\n",
        "      if j == len(sentence)+1:\n",
        "        continue\n",
        "      score_dd = {}\n",
        "      score_dd1 = {}\n",
        "      score_dd2 = {}\n",
        "      score_dd3 = {}\n",
        "      sameparent = 0\n",
        "  \n",
        "      if max(score_matrix1[j])==0:\n",
        "        pred_label.insert(0, random.choice(states[1:-2]))     # if no best path, assign random\n",
        "        #print(\"No best path, heres some mostly random states\")\n",
        "      elif j == len(sentence) or sameparent == 3:             # 2nd last layer, take 3rd best\n",
        "        for u in range(len(states)):\n",
        "          firstscore = score_matrix1[j,u]\n",
        "          secondscore = score_matrix2[j,u]\n",
        "          thirdscore = score_matrix3[j,u]\n",
        "          try:\n",
        "            a = self.transitions[states[u]+' '+previous_max_y]\n",
        "          except:\n",
        "            a = 0\n",
        "          score_dd1[states[u]] = firstscore*a\n",
        "          score_dd2[states[u]] = secondscore*a\n",
        "          score_dd3[states[u]] = thirdscore*a\n",
        "\n",
        "        if max(score_dd3, key=score_dd3.get)==max(score_dd2, key=score_dd2.get) or max(score_dd3, key=score_dd3.get)==max(score_dd1, key=score_dd1.get):\n",
        "          sameparent = 2\n",
        "        if max(score_dd3, key=score_dd3.get)==max(score_dd2, key=score_dd2.get) and max(score_dd3, key=score_dd3.get)==max(score_dd1, key=score_dd1.get):\n",
        "          sameparent = 3\n",
        "        previous_max_y = max(score_dd3, key=score_dd3.get)\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "      elif sameparent == 2:\n",
        "        for u in range(len(states)):\n",
        "          firstscore = score_matrix1[j,u]\n",
        "          secondscore = score_matrix2[j,u]\n",
        "          thirdscore = score_matrix3[j,u]\n",
        "          try:\n",
        "            a = self.transitions[states[u]+' '+previous_max_y]\n",
        "          except:\n",
        "            a = 0\n",
        "          score_dd1[states[u]] = firstscore*a\n",
        "          score_dd2[states[u]] = secondscore*a\n",
        "          score_dd3[states[u]] = thirdscore*a\n",
        "\n",
        "        if max(score_dd3, key=score_dd3.get)==max(score_dd2, key=score_dd2.get) or max(score_dd3, key=score_dd3.get)==max(score_dd1, key=score_dd1.get):\n",
        "          sameparent = 2\n",
        "        if max(score_dd3, key=score_dd3.get)==max(score_dd2, key=score_dd2.get) and max(score_dd3, key=score_dd3.get)==max(score_dd1, key=score_dd1.get):\n",
        "          sameparent = 3\n",
        "        \n",
        "        previous_max_y = max(score_dd2, key=score_dd2.get)\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "      else:                                                    # other layers take best\n",
        "        for u in range(len(states)):\n",
        "          score = score_matrix1[j,u]\n",
        "          try:\n",
        "            a = self.transitions[states[u]+' '+previous_max_y]\n",
        "          except:\n",
        "            a = 0\n",
        "          score_dd[states[u]] = score*a\n",
        "        previous_max_y = max(score_dd, key=score_dd.get)\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "        #print(pred_label)\n",
        "    return pred_label\n",
        "\n",
        "  def run(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    with open ('content/ISTD-50.007-Design-Project-Data/EN/dev.p4.out', 'w') as f:\n",
        "      for i in tqdm(self.sentences):\n",
        "        self.predicted_labels = self.viterbi_sentence(i)\n",
        "        self.predictions.append(self.predicted_labels)\n",
        "        tuplelist = [(i[l], self.predicted_labels[l]) for l in range(len(i))]\n",
        "        for (x, y) in tuplelist:\n",
        "          f.write(x+\" \"+y+\"\\n\")\n",
        "        f.write('\\n')\n",
        "\n",
        "  def runone(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    #print(self.sentences[4])\n",
        "    self.predicted_labels = self.viterbi_sentence(self.sentences[2])\n",
        "    print(self.predicted_labels)\n",
        "\n",
        "\n",
        "balls = viterbi(EN_transitions, EN_emission,EN_states,EN_words,dev_in)\n",
        "balls.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMNcpsTMJCgG"
      },
      "source": [
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p4.out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw_ZW63JOV_5"
      },
      "source": [
        "Part 5 - Second Order HMM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkFl2vsAOYon"
      },
      "source": [
        "# original: a_u,v = count(u,v)/count(u)\n",
        "# try: a_tu,v = count(t,u,v)/count(t,u)\n",
        "\n",
        "def get_second_order_transition_parameters(ls):\n",
        "  arra_y = [i[1] for i in ls]\n",
        "  states = {}\n",
        "  yoyi_count = {}\n",
        "  yoyiy2_count = {}\n",
        "  transition = {}\n",
        "  # to get Count(y)\n",
        "  pervypervy = 'STOP'\n",
        "  pervy = 'STOP'\n",
        "  curry = ''\n",
        "  for y in arra_y:\n",
        "    curry = y\n",
        "    if not y in states:\n",
        "      states[y] = 1\n",
        "    else:\n",
        "      states[y] += 1\n",
        "    # to get count(y0 -> y1)\n",
        "    yoyi = pervy+' '+curry\n",
        "    if not yoyi in yoyi_count:\n",
        "      yoyi_count[yoyi] = 1\n",
        "    else:\n",
        "      yoyi_count[yoyi] += 1\n",
        "    # to get count(y0 -> y1 -> y2)\n",
        "    yoyiy2 = pervypervy+' '+pervy+' '+curry\n",
        "    if not yoyiy2 in yoyiy2_count:\n",
        "      yoyiy2_count[yoyiy2] = 1\n",
        "    else:\n",
        "      yoyiy2_count[yoyiy2] += 1\n",
        "    pervypervy = pervy\n",
        "    pervy = y\n",
        "  # calculate transition parameters\n",
        "  for i,n in yoyiy2_count.items():\n",
        "    y0 = i.split(' ')[0]\n",
        "    y1 = i.split(' ')[1]\n",
        "    # ignore all state transitions of (STOP -> y1) & (STOP -> STOP -> y1)\n",
        "    if y0 == 'STOP' or y1=='STOP':\n",
        "      continue\n",
        "    transition[i] = n/yoyi_count[y0+' '+y1]\n",
        "  return transition\n",
        "\n",
        "\n",
        "\n",
        "dip_shit = read_training_file('content/ISTD-50.007-Design-Project-Data/EN/train')\n",
        "#print(dip_shit[2:4])\n",
        "\n",
        "EN_secondorder_transitions = get_second_order_transition_parameters(dip_shit)\n",
        "print(EN_secondorder_transitions)\n",
        "print(EN_transitions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVWXsSsNwyqN"
      },
      "source": [
        "print(EN_secondorder_transitions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmdgJuSMcVfP"
      },
      "source": [
        "dev_in = read_test_file('content/ISTD-50.007-Design-Project-Data/EN/dev.in')\n",
        "#print(dev_in[-2])\n",
        "\n",
        "\n",
        "class viterbi2:\n",
        "\n",
        "  def __init__(self,transitions,secondordertransitions, emission, states, words, testdata):\n",
        "    self.PROB_MULTIPLIER = 1\n",
        "    self.transitions = transitions\n",
        "    self.secondordertransitions = secondordertransitions\n",
        "    self.emission = emission\n",
        "    ls = list(states.keys())\n",
        "    ls.insert(0, 'START')\n",
        "    ls.append('STOP')\n",
        "    self.all_states = ls\n",
        "    self.testdata = testdata\n",
        "    self.sentence = []\n",
        "    self.words = words\n",
        "    self.predictions = []\n",
        "\n",
        "  def get_predictions(self):\n",
        "    return self.predictions\n",
        "\n",
        "  def test_file_to_sentences(self,testdata):\n",
        "    ls = []\n",
        "    sentences = []\n",
        "    for i in testdata:\n",
        "      if i != '###START###' and i != \"###STOP###\":\n",
        "        ls.append(i)\n",
        "      if i == '###STOP###':\n",
        "        sentences.append(ls)\n",
        "        ls = []\n",
        "    return sentences\n",
        "\n",
        "  def pi(self,layer, current_state_pointer, score_matrix):\n",
        "    mul = self.PROB_MULTIPLIER\n",
        "    sentence = self.sentence\n",
        "    words = self.words\n",
        "    states = self.all_states\n",
        "    current_state = states[current_state_pointer]\n",
        "    # initialization (START layer)\n",
        "    if layer == 0:\n",
        "      if current_state == \"START\":\n",
        "        return 1\n",
        "      else :\n",
        "        return 0\n",
        "    # when we dont have 2 previous states (first layer)\n",
        "    elif layer == 1:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return 0\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:\n",
        "              b = 0\n",
        "          else:\n",
        "            b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          # use first order transition parameter\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix[layer-1,i]*a*b)\n",
        "      return max(ls)\n",
        "\n",
        "    # final step (STOP layer)\n",
        "    elif layer == len(sentence)+1:\n",
        "      ls1 = []\n",
        "      if current_state == \"STOP\":\n",
        "        for i in range(len(states)): # previous layer\n",
        "          for j in range(len(states)): # layer -2\n",
        "            # use second order transitions\n",
        "            try:\n",
        "              a = self.secondordertransitions[states[j]+' '+states[i]+' '+current_state]*mul\n",
        "            except:\n",
        "              a = 0\n",
        "            if np.isnan(score_matrix[layer-1,i]):\n",
        "              ls1.append(self.pi(layer-1,i)*a)\n",
        "            else:\n",
        "              ls1.append(score_matrix[layer-1,i]*a)\n",
        "        return max(ls1)\n",
        "      else:\n",
        "        return 0\n",
        "    # middle layers (for each word in the sentence)\n",
        "    else:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return 0\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:\n",
        "              b = 0\n",
        "          else:\n",
        "            b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          for j in range(len(states)): # layer -2\n",
        "            # use second order transitions\n",
        "            # ignore all START states since we are in the middle of a sentence\n",
        "            if states[j] != 'START':\n",
        "              try:\n",
        "                a = self.secondordertransitions[states[j]+' '+states[i]+' '+current_state]*mul\n",
        "              except:\n",
        "                a = 0\n",
        "              if np.isnan(score_matrix[layer-1,i]):\n",
        "                ls.append(self.pi(layer-1,i)*a*b)\n",
        "              else:\n",
        "                ls.append(score_matrix[layer-1,i]*a*b)\n",
        "            else:\n",
        "              continue\n",
        "      return max(ls)\n",
        "\n",
        "  def viterbi_sentence(self,sentence_testdata):\n",
        "    no_route = None\n",
        "    states = self.all_states\n",
        "    self.sentence = sentence_testdata\n",
        "    sentence = self.sentence\n",
        "    # create empty score matrix to store all pi values\n",
        "    score_matrix = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix[:] = np.NaN\n",
        "    # empty list to store predicted labels\n",
        "    pred_label = []\n",
        "    # viterbi algorithm\n",
        "    for j in range(len(sentence)+2):\n",
        "      for u in range(len(states)):\n",
        "        score = self.pi(j,u, score_matrix)\n",
        "        score_matrix[j,u] = score\n",
        "        #print(\"State: \", self.all_states[u])\n",
        "        #print(\"Score:\",score)\n",
        "      if max(score_matrix[j])==0 and no_route==None:\n",
        "        #print(j-1)\n",
        "        no_route = j-1\n",
        "    #print(score_matrix)\n",
        "\n",
        "    # backtracking\n",
        "    previous_max_y = 'STOP'\n",
        "    for j in range(len(sentence)+1,0,-1):\n",
        "      # ignore STOP layer\n",
        "      if j == len(sentence)+1:\n",
        "        continue\n",
        "      \n",
        "      score_dd = {}\n",
        "      if max(score_matrix[j])==0:\n",
        "        pred_label.insert(0, random.choice(states[1:-2]))\n",
        "      # layer 1\n",
        "      elif j == 1:\n",
        "        for u in range(len(states)): # current layer\n",
        "          score = score_matrix[j,u]\n",
        "          for v in range(len(states)): # layer to the left of current layer\n",
        "            # only consider START state for layer on the left since we are in the first layer\n",
        "            if states[v] == 'START':\n",
        "              try:\n",
        "                a = self.secondordertransitions[states[v]+' '+states[u]+' '+previous_max_y]\n",
        "              except:\n",
        "                a = 0\n",
        "              score_dd[states[v]+' '+states[u]] = score*a\n",
        "\n",
        "        previous_max_key = max(score_dd, key=score_dd.get)\n",
        "        previous_max_y = previous_max_key.split()[1]\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "\n",
        "      # other middle layers\n",
        "      else:\n",
        "        for u in range(len(states)): # current layer\n",
        "          score = score_matrix[j,u]\n",
        "          for v in range(len(states)): # layer to the left of current layer\n",
        "            # ignore START state since we are in the middle of a sentence\n",
        "            if states[v] != 'START' or states[u] != 'START':\n",
        "              try:\n",
        "                a = self.secondordertransitions[states[v]+' '+states[u]+' '+previous_max_y]\n",
        "              except:\n",
        "                a = 0\n",
        "              score_dd[states[v]+' '+states[u]] = score*a\n",
        "\n",
        "        previous_max_key = max(score_dd, key=score_dd.get)\n",
        "        previous_max_y = previous_max_key.split()[1]\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "        #print(pred_label)\n",
        "    return pred_label\n",
        "\n",
        "  def run(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    with open ('content/ISTD-50.007-Design-Project-Data/EN/dev.p5.out', 'w') as f:\n",
        "      for i in tqdm(self.sentences):\n",
        "        self.predicted_labels = self.viterbi_sentence(i)\n",
        "        self.predictions.append(self.predicted_labels)\n",
        "        tuplelist = [(i[l], self.predicted_labels[l]) for l in range(len(i))]\n",
        "        for (x, y) in tuplelist:\n",
        "          f.write(x+\" \"+y+\"\\n\")\n",
        "        f.write('\\n')\n",
        "\n",
        "  def runone(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    print(self.sentences[4])\n",
        "    self.predicted_labels = self.viterbi_sentence(self.sentences[4])\n",
        "    print(self.predicted_labels)\n",
        "\n",
        "\n",
        "balls = viterbi2(EN_transitions,EN_secondorder_transitions, EN_emission,EN_states,EN_words,dev_in)\n",
        "balls.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VItPQrhhMAuf"
      },
      "source": [
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p5.out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCDXy9zxXJfT"
      },
      "source": [
        "EN_emission, EN_states, EN_words = get_emission_parameters(ENtrain, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66XKlJcSQrKz"
      },
      "source": [
        "# Change handling of emission probability\n",
        "\n",
        "class viterbiE:\n",
        "\n",
        "  def __init__(self,transitions, emission, states, words, testdata):\n",
        "    self.PROB_MULTIPLIER = 1\n",
        "    self.transitions = transitions\n",
        "    self.emission = emission\n",
        "    ls = list(states.keys())\n",
        "    ls.insert(0, 'START')\n",
        "    ls.append('STOP')\n",
        "    self.all_states = ls\n",
        "    self.testdata = testdata\n",
        "    self.sentence = []\n",
        "    self.words = words\n",
        "    self.predictions = []\n",
        "\n",
        "  def get_predictions(self):\n",
        "    return self.predictions\n",
        "\n",
        "  def test_file_to_sentences(self,testdata):\n",
        "    ls = []\n",
        "    sentences = []\n",
        "    for i in testdata:\n",
        "      if i != '###START###' and i != \"###STOP###\":\n",
        "        ls.append(i)\n",
        "      if i == '###STOP###':\n",
        "        sentences.append(ls)\n",
        "        ls = []\n",
        "    return sentences\n",
        "\n",
        "  def pi(self,layer, current_state_pointer, score_matrix):\n",
        "    mul = self.PROB_MULTIPLIER\n",
        "    sentence = self.sentence\n",
        "    words = self.words\n",
        "    states = self.all_states\n",
        "    current_state = states[current_state_pointer]\n",
        "    # initialization (START layer)\n",
        "    if layer == 0:\n",
        "      if current_state == \"START\":\n",
        "        return 1\n",
        "      else :\n",
        "        return 0\n",
        "    # final step (STOP layer)\n",
        "    elif layer == len(sentence)+1:\n",
        "      ls1 = []\n",
        "      if current_state == \"STOP\":\n",
        "        for i in range(len(states)):\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix[layer-1,i]):\n",
        "            ls1.append(self.pi(layer-1,i)*a)\n",
        "          else:\n",
        "            ls1.append(score_matrix[layer-1,i]*a)\n",
        "        return max(ls1)\n",
        "      else:\n",
        "        return 0\n",
        "    # middle layers (for each word in the sentence)\n",
        "    else:\n",
        "      ls = []\n",
        "      # loop over v (all states in previous layer)\n",
        "      for i in range(len(states)):\n",
        "        if current_state == 'START' or current_state == \"STOP\":\n",
        "          return 0\n",
        "        else:\n",
        "          # check if word was encountered in training set\n",
        "          if sentence[layer-1] in words:\n",
        "            try:\n",
        "              b = self.emission[current_state+' '+sentence[layer-1]]*mul\n",
        "            except:                \n",
        "              b = 0\n",
        "          # if word not in training set\n",
        "          else:\n",
        "            # try to transform the word and search again\n",
        "            try:\n",
        "              word = sentence[layer-1]\n",
        "              word = word.lower()\n",
        "              # capitalize if first word in sentence\n",
        "              if layer==1:\n",
        "                word = word.capitalize()\n",
        "                b = self.emission[current_state+' '+word]*mul\n",
        "              else:\n",
        "                b = self.emission[current_state+' '+word]*mul\n",
        "            # return UNK probability\n",
        "            except:\n",
        "              b = self.emission[current_state+' '+'#UNK#']*mul\n",
        "          try:\n",
        "            a = self.transitions[states[i]+' '+current_state]*mul\n",
        "          except:\n",
        "            a = 0\n",
        "          if np.isnan(score_matrix[layer-1,i]):\n",
        "            ls.append(self.pi(layer-1,i)*a*b)\n",
        "          else:\n",
        "            ls.append(score_matrix[layer-1,i]*a*b)\n",
        "      return max(ls)\n",
        "\n",
        "  def viterbi_sentence(self,sentence_testdata):\n",
        "    no_route = None\n",
        "    states = self.all_states\n",
        "    self.sentence = sentence_testdata\n",
        "    sentence = self.sentence\n",
        "    # create empty score matrix to store all pi values\n",
        "    score_matrix = np.empty((len(sentence)+2,len(states)))\n",
        "    score_matrix[:] = np.NaN\n",
        "    # empty list to store predicted labels\n",
        "    pred_label = []\n",
        "    # viterbi algorithm\n",
        "    for j in range(len(sentence)+2):\n",
        "      for u in range(len(states)):\n",
        "        score = self.pi(j,u, score_matrix)\n",
        "        score_matrix[j,u] = score\n",
        "        #print(\"State: \", self.all_states[u])\n",
        "        #print(\"Score:\",score)\n",
        "      if max(score_matrix[j])==0 and no_route==None:\n",
        "        #print(j-1)\n",
        "        no_route = j-1\n",
        "    # backtracking\n",
        "    previous_max_y = 'STOP'\n",
        "    for j in range(len(sentence)+1,0,-1):\n",
        "      # ignore STOP layer\n",
        "      if j == len(sentence)+1:\n",
        "        continue\n",
        "      score_dd = {}\n",
        "      if max(score_matrix[j])==0:\n",
        "        pred_label.insert(0, random.choice(states[1:-2]))\n",
        "      else:\n",
        "        for u in range(len(states)):\n",
        "          score = score_matrix[j,u]\n",
        "          try:\n",
        "            a = self.transitions[states[u]+' '+previous_max_y]\n",
        "          except:\n",
        "            a = 0\n",
        "          score_dd[states[u]] = score*a\n",
        "        previous_max_y = max(score_dd, key=score_dd.get)\n",
        "        pred_label.insert(0,previous_max_y)\n",
        "        #print(pred_label)\n",
        "    return pred_label\n",
        "\n",
        "  def run(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    with open ('content/ISTD-50.007-Design-Project-Data/EN/dev.p7.out', 'w') as f:\n",
        "      for i in tqdm(self.sentences):\n",
        "        self.predicted_labels = self.viterbi_sentence(i)\n",
        "        self.predictions.append(self.predicted_labels)\n",
        "        tuplelist = [(i[l], self.predicted_labels[l]) for l in range(len(i))]\n",
        "        for (x, y) in tuplelist:\n",
        "          f.write(x+\" \"+y+\"\\n\")\n",
        "        f.write('\\n')\n",
        "\n",
        "  def runone(self):\n",
        "    self.sentences = self.test_file_to_sentences(self.testdata)\n",
        "    print(self.sentences[1])\n",
        "    self.predicted_labels = self.viterbi_sentence(self.sentences[1])\n",
        "    print(self.predicted_labels)\n",
        "\n",
        "\n",
        "balls = viterbiE(EN_transitions, EN_emission,EN_states,EN_words,dev_in)\n",
        "balls.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq8ad33WWBPR"
      },
      "source": [
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p7.out\r\n",
        "!python3 ISTD-50.007-Design-Project-Data/EvalScript/evalResult.py ISTD-50.007-Design-Project-Data/EN/dev.out ISTD-50.007-Design-Project-Data/EN/dev.p3.out"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}